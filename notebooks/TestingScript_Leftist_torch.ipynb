{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from data import load_data\n",
    "import sklearn\n",
    "import pickle\n",
    "import numpy as np \n",
    "import torch \n",
    "from ClassificationModels.CNN_T import ResNetBaseline, get_all_preds, fit, UCRDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import os "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dataset='GunPoint'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#TODO include OneHot Encoding Options\n",
    "train_x,test_x, train_y, test_y = load_data.load_basic_dataset(dataset,scaling=None,mode='feat',cwd='/media/jacqueline/Data/UCRArchive_2018/')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(test_y.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "enc1=sklearn.preprocessing.OneHotEncoder(sparse=False).fit(np.vstack((train_y.reshape(-1,1),test_y.reshape(-1,1))))\n",
    "pickle.dump(enc1,open(f'./ClassificationModels/models/{dataset}/OneHotEncoder.pkl','wb'))\n",
    "\n",
    "train_y=enc1.transform(train_y.reshape(-1,1))\n",
    "test_y=enc1.transform(test_y.reshape(-1,1))\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "n_pred_classes =train_y.shape[1]\n",
    "train_dataset = UCRDataset(train_x.astype(np.float64),train_y.astype(np.int64))\n",
    "test_dataset = UCRDataset(test_x.astype(np.float64),test_y.astype(np.int64))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=16,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=1,shuffle=False)\n",
    "model = ResNetBaseline(in_channels=1, num_pred_classes=n_pred_classes)\n",
    "fit(model,train_loader,test_loader)\n",
    "if dataset in os.listdir('./ClassificationModels/models/'):\n",
    "    print('Folder exists')\n",
    "else: \n",
    "    os.mkdir(f'./ClassificationModels/models/{dataset}')\n",
    "torch.save(model.state_dict(), f'./ClassificationModels/models/{dataset}/ResNet')\n",
    "\n",
    "test_preds, ground_truth = get_all_preds(model, test_loader)\n",
    "ground_truth=np.argmax(ground_truth,axis=1)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(5,4)})\n",
    "heatmap=confusion_matrix(ground_truth, test_preds)\n",
    "sns.heatmap(heatmap, annot=True)\n",
    "plt.savefig(f'./ClassificationModels/models/{dataset}/ResNet_confusion_matrix.png')\n",
    "plt.close()\n",
    "acc= accuracy_score(ground_truth, test_preds)\n",
    "a = classification_report(ground_truth, test_preds, output_dict=True)\n",
    "dataframe = pd.DataFrame.from_dict(a)\n",
    "dataframe.to_csv(f'./ClassificationModels/models/{dataset}/classification_report.csv', index = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1, Train loss: 0.576, Val loss: 0.689\n",
      "Epoch: 2, Train loss: 0.738, Val loss: 0.706\n",
      "Epoch: 3, Train loss: 0.791, Val loss: 0.706\n",
      "Epoch: 4, Train loss: 0.699, Val loss: 0.699\n",
      "Epoch: 5, Train loss: 0.66, Val loss: 0.74\n",
      "Epoch: 6, Train loss: 0.816, Val loss: 0.703\n",
      "Epoch: 7, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 8, Train loss: 0.693, Val loss: 0.692\n",
      "Epoch: 9, Train loss: 0.691, Val loss: 0.692\n",
      "Epoch: 10, Train loss: 0.691, Val loss: 0.691\n",
      "Epoch: 11, Train loss: 0.683, Val loss: 0.69\n",
      "Epoch: 12, Train loss: 0.711, Val loss: 0.692\n",
      "Epoch: 13, Train loss: 0.699, Val loss: 0.688\n",
      "Epoch: 14, Train loss: 0.672, Val loss: 0.685\n",
      "Epoch: 15, Train loss: 0.685, Val loss: 0.681\n",
      "Epoch: 16, Train loss: 0.691, Val loss: 0.674\n",
      "Epoch: 17, Train loss: 0.675, Val loss: 0.67\n",
      "Epoch: 18, Train loss: 0.698, Val loss: 0.704\n",
      "Epoch: 19, Train loss: 0.701, Val loss: 0.685\n",
      "Epoch: 20, Train loss: 0.683, Val loss: 0.681\n",
      "Epoch: 21, Train loss: 0.68, Val loss: 0.672\n",
      "Epoch: 22, Train loss: 0.674, Val loss: 0.662\n",
      "Epoch: 23, Train loss: 0.692, Val loss: 0.669\n",
      "Epoch: 24, Train loss: 0.695, Val loss: 0.702\n",
      "Epoch: 25, Train loss: 0.707, Val loss: 0.695\n",
      "Epoch: 26, Train loss: 0.698, Val loss: 0.691\n",
      "Epoch: 27, Train loss: 0.687, Val loss: 0.693\n",
      "Epoch: 28, Train loss: 0.697, Val loss: 0.702\n",
      "Epoch: 29, Train loss: 0.673, Val loss: 0.702\n",
      "Epoch: 30, Train loss: 0.698, Val loss: 0.706\n",
      "Epoch: 31, Train loss: 0.698, Val loss: 0.696\n",
      "Epoch: 32, Train loss: 0.694, Val loss: 0.689\n",
      "Epoch: 33, Train loss: 0.691, Val loss: 0.688\n",
      "Epoch: 34, Train loss: 0.683, Val loss: 0.688\n",
      "Epoch: 35, Train loss: 0.69, Val loss: 0.691\n",
      "Epoch: 36, Train loss: 0.673, Val loss: 0.691\n",
      "Epoch: 37, Train loss: 0.657, Val loss: 0.705\n",
      "Epoch: 38, Train loss: 0.658, Val loss: 0.717\n",
      "Epoch: 39, Train loss: 0.66, Val loss: 0.722\n",
      "Epoch: 40, Train loss: 0.696, Val loss: 0.7\n",
      "Epoch: 41, Train loss: 0.671, Val loss: 0.676\n",
      "Epoch: 42, Train loss: 0.674, Val loss: 0.669\n",
      "Epoch: 43, Train loss: 0.658, Val loss: 0.658\n",
      "Epoch: 44, Train loss: 0.61, Val loss: 0.685\n",
      "Epoch: 45, Train loss: 0.665, Val loss: 0.638\n",
      "Epoch: 46, Train loss: 0.644, Val loss: 0.644\n",
      "Epoch: 47, Train loss: 0.644, Val loss: 0.616\n",
      "Epoch: 48, Train loss: 0.581, Val loss: 0.603\n",
      "Epoch: 49, Train loss: 0.625, Val loss: 0.614\n",
      "Epoch: 50, Train loss: 0.645, Val loss: 0.597\n",
      "Epoch: 51, Train loss: 0.655, Val loss: 0.649\n",
      "Epoch: 52, Train loss: 0.58, Val loss: 0.753\n",
      "Epoch: 53, Train loss: 0.709, Val loss: 0.67\n",
      "Epoch: 54, Train loss: 0.698, Val loss: 0.696\n",
      "Epoch: 55, Train loss: 0.714, Val loss: 0.669\n",
      "Epoch: 56, Train loss: 0.64, Val loss: 0.986\n",
      "Epoch: 57, Train loss: 0.711, Val loss: 0.637\n",
      "Epoch: 58, Train loss: 0.603, Val loss: 0.614\n",
      "Epoch: 59, Train loss: 0.565, Val loss: 0.637\n",
      "Epoch: 60, Train loss: 0.627, Val loss: 0.581\n",
      "Epoch: 61, Train loss: 0.604, Val loss: 0.6\n",
      "Epoch: 62, Train loss: 0.622, Val loss: 0.599\n",
      "Epoch: 63, Train loss: 0.537, Val loss: 0.593\n",
      "Epoch: 64, Train loss: 0.951, Val loss: 0.608\n",
      "Epoch: 65, Train loss: 0.68, Val loss: 0.86\n",
      "Epoch: 66, Train loss: 0.787, Val loss: 0.709\n",
      "Epoch: 67, Train loss: 0.689, Val loss: 0.688\n",
      "Epoch: 68, Train loss: 0.683, Val loss: 0.682\n",
      "Epoch: 69, Train loss: 0.707, Val loss: 0.673\n",
      "Epoch: 70, Train loss: 0.652, Val loss: 0.697\n",
      "Epoch: 71, Train loss: 0.8, Val loss: 0.683\n",
      "Epoch: 72, Train loss: 0.689, Val loss: 0.681\n",
      "Epoch: 73, Train loss: 0.686, Val loss: 0.677\n",
      "Epoch: 74, Train loss: 0.667, Val loss: 0.664\n",
      "Epoch: 75, Train loss: 0.632, Val loss: 0.652\n",
      "Epoch: 76, Train loss: 0.725, Val loss: 0.645\n",
      "Epoch: 77, Train loss: 0.64, Val loss: 0.675\n",
      "Epoch: 78, Train loss: 0.629, Val loss: 0.673\n",
      "Epoch: 79, Train loss: 0.656, Val loss: 0.638\n",
      "Epoch: 80, Train loss: 0.605, Val loss: 0.655\n",
      "Epoch: 81, Train loss: 0.546, Val loss: 0.63\n",
      "Epoch: 82, Train loss: 0.635, Val loss: 0.609\n",
      "Epoch: 83, Train loss: 0.658, Val loss: 0.632\n",
      "Epoch: 84, Train loss: 0.554, Val loss: 0.619\n",
      "Epoch: 85, Train loss: 0.627, Val loss: 0.604\n",
      "Epoch: 86, Train loss: 0.625, Val loss: 0.598\n",
      "Epoch: 87, Train loss: 0.614, Val loss: 0.597\n",
      "Epoch: 88, Train loss: 0.539, Val loss: 0.594\n",
      "Epoch: 89, Train loss: 0.604, Val loss: 0.591\n",
      "Epoch: 90, Train loss: 0.522, Val loss: 0.586\n",
      "Epoch: 91, Train loss: 0.568, Val loss: 0.575\n",
      "Epoch: 92, Train loss: 0.65, Val loss: 0.594\n",
      "Epoch: 93, Train loss: 0.792, Val loss: 0.628\n",
      "Epoch: 94, Train loss: 0.659, Val loss: 0.703\n",
      "Epoch: 95, Train loss: 0.706, Val loss: 0.72\n",
      "Epoch: 96, Train loss: 0.712, Val loss: 0.712\n",
      "Epoch: 97, Train loss: 0.704, Val loss: 0.7\n",
      "Epoch: 98, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 99, Train loss: 0.679, Val loss: 0.693\n",
      "Epoch: 100, Train loss: 0.696, Val loss: 0.695\n",
      "Epoch: 101, Train loss: 0.744, Val loss: 0.693\n",
      "Epoch: 102, Train loss: 0.686, Val loss: 0.692\n",
      "Epoch: 103, Train loss: 0.693, Val loss: 0.692\n",
      "Epoch: 104, Train loss: 0.693, Val loss: 0.691\n",
      "Epoch: 105, Train loss: 0.7, Val loss: 0.689\n",
      "Epoch: 106, Train loss: 0.69, Val loss: 0.688\n",
      "Epoch: 107, Train loss: 0.688, Val loss: 0.687\n",
      "Epoch: 108, Train loss: 0.689, Val loss: 0.684\n",
      "Epoch: 109, Train loss: 0.679, Val loss: 0.677\n",
      "Epoch: 110, Train loss: 0.678, Val loss: 0.668\n",
      "Epoch: 111, Train loss: 0.667, Val loss: 0.66\n",
      "Epoch: 112, Train loss: 0.629, Val loss: 0.629\n",
      "Epoch: 113, Train loss: 0.646, Val loss: 0.61\n",
      "Epoch: 114, Train loss: 0.627, Val loss: 0.624\n",
      "Epoch: 115, Train loss: 0.64, Val loss: 0.618\n",
      "Epoch: 116, Train loss: 0.542, Val loss: 0.602\n",
      "Epoch: 117, Train loss: 0.637, Val loss: 0.605\n",
      "Epoch: 118, Train loss: 0.59, Val loss: 0.614\n",
      "Epoch: 119, Train loss: 0.6, Val loss: 0.609\n",
      "Epoch: 120, Train loss: 0.587, Val loss: 0.593\n",
      "Epoch: 121, Train loss: 0.721, Val loss: 0.572\n",
      "Epoch: 122, Train loss: 0.619, Val loss: 0.585\n",
      "Epoch: 123, Train loss: 0.606, Val loss: 0.591\n",
      "Epoch: 124, Train loss: 0.586, Val loss: 0.585\n",
      "Epoch: 125, Train loss: 0.618, Val loss: 0.589\n",
      "Epoch: 126, Train loss: 0.545, Val loss: 0.594\n",
      "Epoch: 127, Train loss: 0.567, Val loss: 0.573\n",
      "Epoch: 128, Train loss: 0.615, Val loss: 0.611\n",
      "Epoch: 129, Train loss: 0.604, Val loss: 0.653\n",
      "Epoch: 130, Train loss: 0.554, Val loss: 0.611\n",
      "Epoch: 131, Train loss: 0.696, Val loss: 0.617\n",
      "Epoch: 132, Train loss: 0.675, Val loss: 0.699\n",
      "Epoch: 133, Train loss: 0.705, Val loss: 0.695\n",
      "Epoch: 134, Train loss: 0.681, Val loss: 0.694\n",
      "Epoch: 135, Train loss: 0.698, Val loss: 0.693\n",
      "Epoch: 136, Train loss: 0.697, Val loss: 0.693\n",
      "Epoch: 137, Train loss: 0.708, Val loss: 0.693\n",
      "Epoch: 138, Train loss: 0.686, Val loss: 0.693\n",
      "Epoch: 139, Train loss: 0.704, Val loss: 0.693\n",
      "Epoch: 140, Train loss: 0.704, Val loss: 0.693\n",
      "Epoch: 141, Train loss: 0.695, Val loss: 0.693\n",
      "Epoch: 142, Train loss: 0.695, Val loss: 0.693\n",
      "Epoch: 143, Train loss: 0.702, Val loss: 0.693\n",
      "Epoch: 144, Train loss: 0.701, Val loss: 0.693\n",
      "Epoch: 145, Train loss: 0.7, Val loss: 0.693\n",
      "Epoch: 146, Train loss: 0.694, Val loss: 0.694\n",
      "Epoch: 147, Train loss: 0.695, Val loss: 0.695\n",
      "Epoch: 148, Train loss: 0.697, Val loss: 0.698\n",
      "Epoch: 149, Train loss: 0.707, Val loss: 0.697\n",
      "Epoch: 150, Train loss: 0.698, Val loss: 0.694\n",
      "Epoch: 151, Train loss: 0.698, Val loss: 0.693\n",
      "Epoch: 152, Train loss: 0.698, Val loss: 0.693\n",
      "Epoch: 153, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 154, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 155, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 156, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 157, Train loss: 0.691, Val loss: 0.693\n",
      "Epoch: 158, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 159, Train loss: 0.691, Val loss: 0.693\n",
      "Epoch: 160, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 161, Train loss: 0.691, Val loss: 0.693\n",
      "Epoch: 162, Train loss: 0.69, Val loss: 0.693\n",
      "Epoch: 163, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 164, Train loss: 0.698, Val loss: 0.693\n",
      "Epoch: 165, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 166, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 167, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 168, Train loss: 0.697, Val loss: 0.693\n",
      "Epoch: 169, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 170, Train loss: 0.691, Val loss: 0.693\n",
      "Epoch: 171, Train loss: 0.691, Val loss: 0.693\n",
      "Epoch: 172, Train loss: 0.697, Val loss: 0.693\n",
      "Epoch: 173, Train loss: 0.696, Val loss: 0.693\n",
      "Epoch: 174, Train loss: 0.696, Val loss: 0.693\n",
      "Epoch: 175, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 176, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 177, Train loss: 0.692, Val loss: 0.693\n",
      "Epoch: 178, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 179, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 180, Train loss: 0.692, Val loss: 0.693\n",
      "Epoch: 181, Train loss: 0.695, Val loss: 0.693\n",
      "Epoch: 182, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 183, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 184, Train loss: 0.696, Val loss: 0.693\n",
      "Epoch: 185, Train loss: 0.692, Val loss: 0.693\n",
      "Epoch: 186, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 187, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 188, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 189, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 190, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 191, Train loss: 0.697, Val loss: 0.693\n",
      "Epoch: 192, Train loss: 0.691, Val loss: 0.693\n",
      "Epoch: 193, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 194, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 195, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 196, Train loss: 0.692, Val loss: 0.693\n",
      "Epoch: 197, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 198, Train loss: 0.692, Val loss: 0.693\n",
      "Epoch: 199, Train loss: 0.692, Val loss: 0.692\n",
      "Epoch: 200, Train loss: 0.691, Val loss: 0.692\n",
      "Epoch: 201, Train loss: 0.686, Val loss: 0.692\n",
      "Epoch: 202, Train loss: 0.685, Val loss: 0.692\n",
      "Epoch: 203, Train loss: 0.69, Val loss: 0.691\n",
      "Epoch: 204, Train loss: 0.701, Val loss: 0.69\n",
      "Epoch: 205, Train loss: 0.687, Val loss: 0.688\n",
      "Epoch: 206, Train loss: 0.698, Val loss: 0.689\n",
      "Epoch: 207, Train loss: 0.688, Val loss: 0.688\n",
      "Epoch: 208, Train loss: 0.7, Val loss: 0.688\n",
      "Epoch: 209, Train loss: 0.692, Val loss: 0.693\n",
      "Epoch: 210, Train loss: 0.698, Val loss: 0.693\n",
      "Epoch: 211, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 212, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 213, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 214, Train loss: 0.692, Val loss: 0.693\n",
      "Epoch: 215, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 216, Train loss: 0.692, Val loss: 0.693\n",
      "Epoch: 217, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 218, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 219, Train loss: 0.693, Val loss: 0.693\n",
      "Epoch: 220, Train loss: 0.694, Val loss: 0.693\n",
      "Epoch: 221, Train loss: 0.692, Val loss: 0.693\n",
      "Early stopping!\n",
      "Folder exists\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/jacqueline/.local/share/virtualenvs/InterpretabiltyTimeSeries-y2AnfPaS/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jacqueline/.local/share/virtualenvs/InterpretabiltyTimeSeries-y2AnfPaS/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jacqueline/.local/share/virtualenvs/InterpretabiltyTimeSeries-y2AnfPaS/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Explanation Algo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "explained_instance = train_x[0]\n",
    "nb_interpretable_feature = 10\n",
    "explanation_size = 5\n",
    "nb_neighbors = 1000\n",
    "learning_process_name = 'Lime'\n",
    "transform_name = 'straight_line'\n",
    "model_to_explain=model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from InterpretabilityModels.leftist.LEFTIST import LEFTIST\n",
    "from InterpretabilityModels.leftist.timeseries.segmentator.uniform_segmentator import UniformSegmentator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "segmentator = UniformSegmentator(nb_interpretable_feature)\n",
    "leftist = LEFTIST(test_x,'straight_line',segmentator,model_to_explain,learning_process_name,mode='feat', backend='torch')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "explanations = leftist.explain(np.array(explained_instance),1000,explanation_size=explanation_size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Instance (1, 150)\n",
      "nb_features 10\n",
      "nb_neighbors 1000\n",
      "NM [[0 0 1 ... 1 0 1]\n",
      " [1 1 1 ... 1 0 1]\n",
      " [0 1 1 ... 1 0 1]\n",
      " ...\n",
      " [1 1 0 ... 0 0 1]\n",
      " [0 0 0 ... 1 1 0]\n",
      " [0 1 0 ... 1 1 0]]\n",
      "masks : \n",
      " [[1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 0 1]\n",
      " [0 1 1 ... 1 0 1]\n",
      " ...\n",
      " [1 1 0 ... 0 0 1]\n",
      " [0 0 0 ... 1 1 0]\n",
      " [0 1 0 ... 1 1 0]] \n",
      " kernel_weights : \n",
      " None \n",
      " values : \n",
      " None \n",
      " proba_labels : \n",
      " None \n",
      " \n",
      "NV [[[-0.6478854 ]\n",
      "  [-0.64199155]\n",
      "  [-0.63818632]\n",
      "  ...\n",
      "  [-0.64042873]\n",
      "  [-0.63866571]\n",
      "  [-0.63865722]]\n",
      "\n",
      " [[-0.6478854 ]\n",
      "  [-0.64199155]\n",
      "  [-0.63818632]\n",
      "  ...\n",
      "  [-0.64042873]\n",
      "  [-0.63866571]\n",
      "  [-0.63865722]]\n",
      "\n",
      " [[-0.6478854 ]\n",
      "  [-0.64875881]\n",
      "  [-0.64963223]\n",
      "  ...\n",
      "  [-0.64042873]\n",
      "  [-0.63866571]\n",
      "  [-0.63865722]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.6478854 ]\n",
      "  [-0.64199155]\n",
      "  [-0.63818632]\n",
      "  ...\n",
      "  [-0.64042873]\n",
      "  [-0.63866571]\n",
      "  [-0.63865722]]\n",
      "\n",
      " [[-0.6478854 ]\n",
      "  [-0.64875881]\n",
      "  [-0.64963223]\n",
      "  ...\n",
      "  [-0.63824779]\n",
      "  [-0.6384525 ]\n",
      "  [-0.63865722]]\n",
      "\n",
      " [[-0.6478854 ]\n",
      "  [-0.64875881]\n",
      "  [-0.64963223]\n",
      "  ...\n",
      "  [-0.63824779]\n",
      "  [-0.6384525 ]\n",
      "  [-0.63865722]]]\n",
      "dis [0.         0.16333997 0.22540333 0.10557281 0.22540333 0.45227744\n",
      " 0.36754447 0.22540333 0.5527864  0.22540333 0.22540333 0.22540333\n",
      " 0.45227744 0.36754447 0.16333997 0.36754447 0.36754447 0.29289322\n",
      " 0.45227744 0.16333997 0.0513167  0.16333997 0.10557281 0.29289322\n",
      " 0.45227744 0.10557281 0.29289322 0.29289322 0.10557281 0.5527864\n",
      " 0.22540333 0.29289322 0.36754447 0.45227744 0.36754447 0.5527864\n",
      " 0.36754447 0.16333997 0.36754447 0.10557281 0.36754447 0.29289322\n",
      " 0.5527864  0.36754447 0.29289322 0.22540333 0.16333997 0.22540333\n",
      " 0.36754447 0.16333997 0.29289322 0.45227744 0.45227744 0.16333997\n",
      " 0.45227744 0.29289322 0.10557281 0.22540333 0.5527864  0.22540333\n",
      " 0.29289322 0.36754447 0.45227744 0.5527864  0.22540333 0.36754447\n",
      " 0.22540333 0.16333997 0.16333997 0.22540333 0.16333997 0.10557281\n",
      " 0.16333997 0.22540333 0.29289322 0.16333997 0.29289322 0.36754447\n",
      " 0.45227744 0.22540333 0.29289322 0.36754447 0.5527864  0.29289322\n",
      " 0.36754447 0.22540333 0.36754447 0.16333997 0.16333997 0.36754447\n",
      " 0.45227744 0.29289322 0.29289322 0.10557281 0.16333997 0.22540333\n",
      " 0.16333997 0.22540333 0.16333997 0.16333997 0.29289322 0.10557281\n",
      " 0.29289322 0.29289322 0.29289322 0.16333997 0.22540333 0.10557281\n",
      " 0.22540333 0.36754447 0.45227744 0.36754447 0.36754447 0.5527864\n",
      " 0.22540333 0.22540333 0.29289322 0.29289322 0.45227744 0.16333997\n",
      " 0.29289322 0.36754447 0.5527864  0.16333997 0.29289322 0.29289322\n",
      " 0.16333997 0.22540333 0.10557281 0.5527864  0.22540333 0.45227744\n",
      " 0.36754447 0.29289322 0.16333997 0.22540333 0.45227744 0.22540333\n",
      " 0.22540333 0.36754447 0.45227744 0.29289322 0.22540333 0.5527864\n",
      " 0.29289322 0.22540333 0.29289322 0.45227744 0.36754447 0.29289322\n",
      " 0.29289322 0.29289322 0.36754447 0.16333997 0.45227744 0.29289322\n",
      " 0.10557281 0.29289322 0.22540333 0.36754447 0.22540333 0.29289322\n",
      " 0.22540333 0.22540333 0.22540333 0.45227744 0.10557281 0.10557281\n",
      " 0.16333997 0.29289322 0.36754447 0.36754447 0.16333997 0.16333997\n",
      " 0.45227744 0.36754447 0.5527864  0.36754447 0.29289322 0.29289322\n",
      " 0.5527864  0.29289322 0.16333997 0.22540333 0.45227744 0.16333997\n",
      " 0.22540333 0.22540333 0.29289322 0.29289322 0.29289322 0.16333997\n",
      " 0.36754447 0.5527864  0.16333997 0.5527864  0.5527864  0.36754447\n",
      " 0.36754447 0.22540333 0.36754447 0.16333997 0.29289322 0.29289322\n",
      " 0.22540333 0.22540333 0.29289322 0.10557281 0.45227744 0.29289322\n",
      " 0.29289322 0.22540333 0.29289322 0.16333997 0.22540333 0.29289322\n",
      " 0.29289322 0.29289322 0.36754447 0.10557281 0.36754447 0.10557281\n",
      " 0.29289322 0.36754447 0.45227744 0.29289322 0.16333997 0.36754447\n",
      " 0.29289322 0.29289322 0.22540333 0.29289322 0.22540333 0.22540333\n",
      " 0.29289322 0.29289322 0.5527864  0.36754447 0.36754447 0.10557281\n",
      " 0.16333997 0.36754447 0.22540333 0.22540333 0.16333997 0.29289322\n",
      " 0.45227744 0.10557281 0.16333997 0.36754447 0.16333997 0.29289322\n",
      " 0.36754447 0.45227744 0.16333997 0.22540333 0.45227744 0.10557281\n",
      " 0.22540333 0.36754447 0.36754447 0.16333997 0.22540333 0.16333997\n",
      " 0.29289322 0.22540333 0.29289322 0.36754447 0.16333997 0.10557281\n",
      " 0.22540333 0.29289322 0.45227744 0.5527864  0.22540333 0.22540333\n",
      " 0.22540333 0.36754447 0.29289322 0.5527864  0.22540333 0.22540333\n",
      " 0.22540333 0.36754447 0.29289322 0.22540333 0.16333997 0.45227744\n",
      " 0.29289322 0.29289322 0.29289322 0.29289322 0.36754447 0.22540333\n",
      " 0.10557281 0.22540333 0.36754447 0.36754447 0.29289322 0.36754447\n",
      " 0.45227744 0.45227744 0.36754447 0.16333997 0.16333997 0.36754447\n",
      " 0.10557281 0.29289322 0.22540333 0.16333997 0.36754447 0.29289322\n",
      " 0.36754447 0.36754447 0.22540333 0.45227744 0.16333997 0.36754447\n",
      " 0.36754447 0.29289322 0.29289322 0.45227744 0.36754447 0.36754447\n",
      " 0.45227744 0.36754447 0.22540333 0.29289322 0.36754447 0.36754447\n",
      " 0.45227744 0.36754447 0.16333997 0.36754447 0.22540333 0.29289322\n",
      " 0.45227744 0.22540333 0.45227744 0.29289322 0.36754447 0.29289322\n",
      " 0.29289322 0.45227744 0.29289322 0.22540333 0.22540333 0.22540333\n",
      " 0.45227744 0.45227744 0.29289322 0.29289322 0.5527864  0.29289322\n",
      " 0.36754447 0.36754447 0.29289322 0.45227744 0.10557281 0.36754447\n",
      " 0.45227744 0.10557281 0.22540333 0.10557281 0.36754447 0.22540333\n",
      " 0.45227744 0.36754447 0.45227744 0.22540333 0.29289322 0.29289322\n",
      " 0.22540333 0.10557281 0.5527864  0.22540333 0.29289322 0.36754447\n",
      " 0.10557281 0.45227744 0.36754447 0.16333997 0.45227744 0.36754447\n",
      " 0.29289322 0.29289322 0.10557281 0.29289322 0.16333997 0.45227744\n",
      " 0.36754447 0.29289322 0.0513167  0.36754447 0.29289322 0.29289322\n",
      " 0.45227744 0.45227744 0.29289322 0.22540333 0.22540333 0.29289322\n",
      " 0.36754447 0.36754447 0.29289322 0.22540333 0.29289322 0.45227744\n",
      " 0.36754447 0.29289322 0.22540333 0.29289322 0.45227744 0.16333997\n",
      " 0.29289322 0.10557281 0.16333997 0.22540333 0.29289322 0.16333997\n",
      " 0.36754447 0.29289322 0.29289322 0.29289322 0.29289322 0.16333997\n",
      " 0.29289322 0.29289322 0.0513167  0.5527864  0.36754447 0.36754447\n",
      " 0.36754447 0.29289322 0.22540333 0.36754447 0.22540333 0.10557281\n",
      " 0.29289322 0.29289322 0.36754447 0.36754447 0.36754447 0.10557281\n",
      " 0.36754447 0.29289322 0.29289322 0.16333997 0.45227744 0.22540333\n",
      " 0.16333997 0.5527864  0.36754447 0.16333997 0.22540333 0.22540333\n",
      " 0.29289322 0.22540333 0.36754447 0.22540333 0.29289322 0.45227744\n",
      " 0.45227744 0.36754447 0.36754447 0.45227744 0.16333997 0.29289322\n",
      " 0.22540333 0.22540333 0.16333997 0.16333997 0.22540333 0.29289322\n",
      " 0.10557281 0.36754447 0.45227744 0.29289322 0.10557281 0.29289322\n",
      " 0.22540333 0.29289322 0.29289322 0.22540333 0.22540333 0.36754447\n",
      " 0.22540333 0.68377223 0.36754447 0.29289322 0.22540333 0.22540333\n",
      " 0.45227744 0.29289322 0.22540333 0.22540333 0.36754447 0.36754447\n",
      " 0.16333997 0.45227744 0.45227744 0.45227744 0.22540333 0.45227744\n",
      " 0.45227744 0.29289322 0.29289322 0.29289322 0.45227744 0.22540333\n",
      " 0.36754447 0.16333997 0.0513167  0.22540333 0.29289322 0.29289322\n",
      " 0.16333997 0.5527864  0.22540333 0.29289322 0.36754447 0.36754447\n",
      " 0.36754447 0.29289322 0.22540333 0.29289322 0.36754447 0.68377223\n",
      " 0.45227744 0.68377223 0.45227744 0.5527864  0.36754447 0.22540333\n",
      " 0.36754447 0.22540333 0.45227744 0.29289322 0.36754447 0.45227744\n",
      " 0.29289322 0.10557281 0.36754447 0.36754447 0.22540333 0.29289322\n",
      " 0.36754447 0.29289322 0.22540333 0.16333997 0.16333997 0.22540333\n",
      " 0.10557281 0.22540333 0.29289322 0.22540333 0.45227744 0.16333997\n",
      " 0.16333997 0.10557281 0.45227744 0.16333997 0.45227744 0.36754447\n",
      " 0.29289322 0.29289322 0.36754447 0.22540333 0.45227744 0.45227744\n",
      " 0.29289322 0.68377223 0.16333997 0.10557281 0.36754447 0.29289322\n",
      " 0.36754447 0.22540333 0.29289322 0.29289322 0.36754447 0.36754447\n",
      " 0.16333997 0.29289322 0.45227744 0.36754447 0.29289322 0.29289322\n",
      " 0.22540333 0.5527864  0.36754447 0.29289322 0.36754447 0.0513167\n",
      " 0.36754447 0.36754447 0.36754447 0.36754447 0.29289322 0.5527864\n",
      " 0.22540333 0.45227744 0.16333997 0.36754447 0.36754447 0.45227744\n",
      " 0.36754447 0.36754447 0.36754447 0.22540333 0.29289322 0.0513167\n",
      " 0.36754447 0.16333997 0.         0.36754447 0.22540333 0.16333997\n",
      " 0.36754447 0.45227744 0.16333997 0.29289322 0.29289322 0.29289322\n",
      " 0.36754447 0.29289322 0.16333997 0.22540333 0.29289322 0.36754447\n",
      " 0.29289322 0.36754447 0.29289322 0.5527864  0.45227744 0.36754447\n",
      " 0.22540333 0.36754447 0.22540333 0.29289322 0.16333997 0.29289322\n",
      " 0.29289322 0.22540333 0.16333997 0.29289322 0.36754447 0.36754447\n",
      " 0.29289322 0.45227744 0.36754447 0.22540333 0.36754447 0.22540333\n",
      " 0.22540333 0.29289322 0.29289322 0.22540333 0.5527864  0.45227744\n",
      " 0.36754447 0.10557281 0.29289322 0.16333997 0.29289322 0.36754447\n",
      " 0.45227744 0.29289322 0.45227744 0.16333997 0.36754447 0.29289322\n",
      " 0.29289322 0.45227744 0.22540333 0.29289322 0.45227744 0.29289322\n",
      " 0.36754447 0.29289322 0.22540333 0.36754447 0.29289322 0.22540333\n",
      " 0.16333997 0.16333997 0.29289322 0.36754447 0.16333997 0.10557281\n",
      " 0.10557281 0.29289322 0.22540333 0.22540333 0.22540333 0.22540333\n",
      " 0.22540333 0.29289322 0.68377223 0.16333997 0.22540333 0.45227744\n",
      " 0.45227744 0.5527864  0.22540333 0.5527864  0.22540333 0.5527864\n",
      " 0.45227744 0.22540333 0.29289322 0.16333997 0.10557281 0.29289322\n",
      " 0.22540333 0.10557281 0.22540333 0.45227744 0.22540333 0.16333997\n",
      " 0.29289322 0.16333997 0.16333997 0.5527864  0.22540333 0.29289322\n",
      " 0.29289322 0.16333997 0.22540333 0.22540333 0.22540333 0.22540333\n",
      " 0.36754447 0.45227744 0.5527864  0.45227744 0.22540333 0.22540333\n",
      " 0.16333997 0.16333997 0.5527864  0.45227744 0.5527864  0.16333997\n",
      " 0.45227744 0.22540333 0.16333997 0.45227744 0.36754447 0.29289322\n",
      " 0.10557281 0.16333997 0.36754447 0.22540333 0.10557281 0.22540333\n",
      " 0.36754447 0.68377223 0.16333997 0.36754447 0.29289322 0.22540333\n",
      " 0.22540333 0.29289322 0.22540333 0.22540333 0.45227744 0.22540333\n",
      " 0.16333997 0.29289322 0.22540333 0.29289322 0.29289322 0.68377223\n",
      " 0.22540333 1.         0.29289322 0.5527864  0.45227744 0.22540333\n",
      " 0.22540333 0.36754447 0.36754447 0.16333997 0.29289322 0.22540333\n",
      " 0.16333997 0.16333997 0.36754447 0.45227744 0.5527864  0.45227744\n",
      " 0.36754447 0.36754447 0.10557281 0.36754447 0.5527864  0.36754447\n",
      " 0.36754447 0.29289322 0.29289322 0.36754447 0.29289322 0.16333997\n",
      " 0.16333997 0.29289322 0.22540333 0.29289322 0.36754447 0.68377223\n",
      " 0.45227744 0.36754447 0.16333997 0.29289322 0.22540333 0.45227744\n",
      " 0.16333997 0.22540333 0.45227744 0.29289322 0.22540333 0.45227744\n",
      " 0.36754447 0.36754447 0.0513167  0.22540333 0.22540333 0.36754447\n",
      " 0.29289322 0.22540333 0.29289322 0.36754447 0.45227744 0.68377223\n",
      " 0.22540333 0.0513167  0.29289322 0.16333997 0.36754447 0.22540333\n",
      " 0.22540333 0.29289322 0.29289322 0.10557281 0.10557281 0.29289322\n",
      " 0.36754447 0.68377223 0.10557281 0.29289322 0.36754447 0.36754447\n",
      " 0.45227744 0.45227744 0.10557281 0.36754447 0.22540333 0.29289322\n",
      " 0.29289322 0.36754447 0.22540333 0.45227744 0.45227744 0.29289322\n",
      " 0.36754447 0.16333997 0.45227744 0.22540333 0.10557281 0.36754447\n",
      " 0.16333997 0.22540333 0.29289322 0.16333997 0.22540333 0.45227744\n",
      " 0.45227744 0.45227744 0.29289322 0.29289322 0.68377223 0.29289322\n",
      " 0.36754447 0.16333997 0.5527864  0.45227744 0.29289322 0.45227744\n",
      " 0.16333997 0.22540333 0.36754447 0.29289322 0.45227744 0.29289322\n",
      " 0.22540333 0.36754447 0.36754447 0.22540333 0.16333997 0.29289322\n",
      " 0.0513167  0.36754447 0.22540333 0.5527864  0.10557281 0.36754447\n",
      " 0.36754447 0.36754447 0.36754447 0.45227744 0.36754447 0.29289322\n",
      " 0.22540333 0.16333997 0.29289322 0.29289322 0.36754447 0.29289322\n",
      " 0.0513167  0.45227744 0.22540333 0.22540333 0.36754447 0.29289322\n",
      " 0.29289322 0.22540333 0.29289322 0.10557281 0.29289322 0.22540333\n",
      " 0.5527864  0.29289322 0.22540333 0.36754447 0.16333997 0.22540333\n",
      " 0.36754447 0.22540333 0.16333997 0.29289322 0.10557281 0.16333997\n",
      " 0.45227744 0.16333997 0.45227744 0.16333997 0.22540333 0.5527864\n",
      " 0.29289322 0.16333997 0.45227744 0.22540333 0.10557281 0.45227744\n",
      " 0.29289322 0.22540333 0.36754447 0.36754447 0.22540333 0.5527864\n",
      " 0.36754447 0.29289322 0.16333997 0.22540333 0.10557281 0.29289322\n",
      " 0.45227744 0.22540333 0.22540333 0.5527864  0.16333997 0.29289322\n",
      " 0.36754447 0.22540333 0.22540333 0.36754447 0.16333997 0.36754447\n",
      " 0.29289322 0.22540333 0.29289322 0.29289322 0.29289322 0.36754447\n",
      " 0.29289322 0.45227744 0.29289322 0.29289322 0.36754447 0.29289322\n",
      " 0.29289322 0.45227744 0.29289322 0.22540333 0.22540333 0.5527864\n",
      " 0.22540333 0.29289322 0.36754447 0.29289322]\n",
      "neigh11 masks : \n",
      " [[1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 0 1]\n",
      " [0 1 1 ... 1 0 1]\n",
      " ...\n",
      " [1 1 0 ... 0 0 1]\n",
      " [0 0 0 ... 1 1 0]\n",
      " [0 1 0 ... 1 1 0]] \n",
      " kernel_weights : \n",
      " [1.00000000e+00 8.07800970e-01 6.66008203e-01 9.14694688e-01\n",
      " 6.66008203e-01 1.94672021e-01 3.39353994e-01 6.66008203e-01\n",
      " 8.67623531e-02 6.66008203e-01 6.66008203e-01 6.66008203e-01\n",
      " 1.94672021e-01 3.39353994e-01 8.07800970e-01 3.39353994e-01\n",
      " 3.39353994e-01 5.03439617e-01 1.94672021e-01 8.07800970e-01\n",
      " 9.79153133e-01 8.07800970e-01 9.14694688e-01 5.03439617e-01\n",
      " 1.94672021e-01 9.14694688e-01 5.03439617e-01 5.03439617e-01\n",
      " 9.14694688e-01 8.67623531e-02 6.66008203e-01 5.03439617e-01\n",
      " 3.39353994e-01 1.94672021e-01 3.39353994e-01 8.67623531e-02\n",
      " 3.39353994e-01 8.07800970e-01 3.39353994e-01 9.14694688e-01\n",
      " 3.39353994e-01 5.03439617e-01 8.67623531e-02 3.39353994e-01\n",
      " 5.03439617e-01 6.66008203e-01 8.07800970e-01 6.66008203e-01\n",
      " 3.39353994e-01 8.07800970e-01 5.03439617e-01 1.94672021e-01\n",
      " 1.94672021e-01 8.07800970e-01 1.94672021e-01 5.03439617e-01\n",
      " 9.14694688e-01 6.66008203e-01 8.67623531e-02 6.66008203e-01\n",
      " 5.03439617e-01 3.39353994e-01 1.94672021e-01 8.67623531e-02\n",
      " 6.66008203e-01 3.39353994e-01 6.66008203e-01 8.07800970e-01\n",
      " 8.07800970e-01 6.66008203e-01 8.07800970e-01 9.14694688e-01\n",
      " 8.07800970e-01 6.66008203e-01 5.03439617e-01 8.07800970e-01\n",
      " 5.03439617e-01 3.39353994e-01 1.94672021e-01 6.66008203e-01\n",
      " 5.03439617e-01 3.39353994e-01 8.67623531e-02 5.03439617e-01\n",
      " 3.39353994e-01 6.66008203e-01 3.39353994e-01 8.07800970e-01\n",
      " 8.07800970e-01 3.39353994e-01 1.94672021e-01 5.03439617e-01\n",
      " 5.03439617e-01 9.14694688e-01 8.07800970e-01 6.66008203e-01\n",
      " 8.07800970e-01 6.66008203e-01 8.07800970e-01 8.07800970e-01\n",
      " 5.03439617e-01 9.14694688e-01 5.03439617e-01 5.03439617e-01\n",
      " 5.03439617e-01 8.07800970e-01 6.66008203e-01 9.14694688e-01\n",
      " 6.66008203e-01 3.39353994e-01 1.94672021e-01 3.39353994e-01\n",
      " 3.39353994e-01 8.67623531e-02 6.66008203e-01 6.66008203e-01\n",
      " 5.03439617e-01 5.03439617e-01 1.94672021e-01 8.07800970e-01\n",
      " 5.03439617e-01 3.39353994e-01 8.67623531e-02 8.07800970e-01\n",
      " 5.03439617e-01 5.03439617e-01 8.07800970e-01 6.66008203e-01\n",
      " 9.14694688e-01 8.67623531e-02 6.66008203e-01 1.94672021e-01\n",
      " 3.39353994e-01 5.03439617e-01 8.07800970e-01 6.66008203e-01\n",
      " 1.94672021e-01 6.66008203e-01 6.66008203e-01 3.39353994e-01\n",
      " 1.94672021e-01 5.03439617e-01 6.66008203e-01 8.67623531e-02\n",
      " 5.03439617e-01 6.66008203e-01 5.03439617e-01 1.94672021e-01\n",
      " 3.39353994e-01 5.03439617e-01 5.03439617e-01 5.03439617e-01\n",
      " 3.39353994e-01 8.07800970e-01 1.94672021e-01 5.03439617e-01\n",
      " 9.14694688e-01 5.03439617e-01 6.66008203e-01 3.39353994e-01\n",
      " 6.66008203e-01 5.03439617e-01 6.66008203e-01 6.66008203e-01\n",
      " 6.66008203e-01 1.94672021e-01 9.14694688e-01 9.14694688e-01\n",
      " 8.07800970e-01 5.03439617e-01 3.39353994e-01 3.39353994e-01\n",
      " 8.07800970e-01 8.07800970e-01 1.94672021e-01 3.39353994e-01\n",
      " 8.67623531e-02 3.39353994e-01 5.03439617e-01 5.03439617e-01\n",
      " 8.67623531e-02 5.03439617e-01 8.07800970e-01 6.66008203e-01\n",
      " 1.94672021e-01 8.07800970e-01 6.66008203e-01 6.66008203e-01\n",
      " 5.03439617e-01 5.03439617e-01 5.03439617e-01 8.07800970e-01\n",
      " 3.39353994e-01 8.67623531e-02 8.07800970e-01 8.67623531e-02\n",
      " 8.67623531e-02 3.39353994e-01 3.39353994e-01 6.66008203e-01\n",
      " 3.39353994e-01 8.07800970e-01 5.03439617e-01 5.03439617e-01\n",
      " 6.66008203e-01 6.66008203e-01 5.03439617e-01 9.14694688e-01\n",
      " 1.94672021e-01 5.03439617e-01 5.03439617e-01 6.66008203e-01\n",
      " 5.03439617e-01 8.07800970e-01 6.66008203e-01 5.03439617e-01\n",
      " 5.03439617e-01 5.03439617e-01 3.39353994e-01 9.14694688e-01\n",
      " 3.39353994e-01 9.14694688e-01 5.03439617e-01 3.39353994e-01\n",
      " 1.94672021e-01 5.03439617e-01 8.07800970e-01 3.39353994e-01\n",
      " 5.03439617e-01 5.03439617e-01 6.66008203e-01 5.03439617e-01\n",
      " 6.66008203e-01 6.66008203e-01 5.03439617e-01 5.03439617e-01\n",
      " 8.67623531e-02 3.39353994e-01 3.39353994e-01 9.14694688e-01\n",
      " 8.07800970e-01 3.39353994e-01 6.66008203e-01 6.66008203e-01\n",
      " 8.07800970e-01 5.03439617e-01 1.94672021e-01 9.14694688e-01\n",
      " 8.07800970e-01 3.39353994e-01 8.07800970e-01 5.03439617e-01\n",
      " 3.39353994e-01 1.94672021e-01 8.07800970e-01 6.66008203e-01\n",
      " 1.94672021e-01 9.14694688e-01 6.66008203e-01 3.39353994e-01\n",
      " 3.39353994e-01 8.07800970e-01 6.66008203e-01 8.07800970e-01\n",
      " 5.03439617e-01 6.66008203e-01 5.03439617e-01 3.39353994e-01\n",
      " 8.07800970e-01 9.14694688e-01 6.66008203e-01 5.03439617e-01\n",
      " 1.94672021e-01 8.67623531e-02 6.66008203e-01 6.66008203e-01\n",
      " 6.66008203e-01 3.39353994e-01 5.03439617e-01 8.67623531e-02\n",
      " 6.66008203e-01 6.66008203e-01 6.66008203e-01 3.39353994e-01\n",
      " 5.03439617e-01 6.66008203e-01 8.07800970e-01 1.94672021e-01\n",
      " 5.03439617e-01 5.03439617e-01 5.03439617e-01 5.03439617e-01\n",
      " 3.39353994e-01 6.66008203e-01 9.14694688e-01 6.66008203e-01\n",
      " 3.39353994e-01 3.39353994e-01 5.03439617e-01 3.39353994e-01\n",
      " 1.94672021e-01 1.94672021e-01 3.39353994e-01 8.07800970e-01\n",
      " 8.07800970e-01 3.39353994e-01 9.14694688e-01 5.03439617e-01\n",
      " 6.66008203e-01 8.07800970e-01 3.39353994e-01 5.03439617e-01\n",
      " 3.39353994e-01 3.39353994e-01 6.66008203e-01 1.94672021e-01\n",
      " 8.07800970e-01 3.39353994e-01 3.39353994e-01 5.03439617e-01\n",
      " 5.03439617e-01 1.94672021e-01 3.39353994e-01 3.39353994e-01\n",
      " 1.94672021e-01 3.39353994e-01 6.66008203e-01 5.03439617e-01\n",
      " 3.39353994e-01 3.39353994e-01 1.94672021e-01 3.39353994e-01\n",
      " 8.07800970e-01 3.39353994e-01 6.66008203e-01 5.03439617e-01\n",
      " 1.94672021e-01 6.66008203e-01 1.94672021e-01 5.03439617e-01\n",
      " 3.39353994e-01 5.03439617e-01 5.03439617e-01 1.94672021e-01\n",
      " 5.03439617e-01 6.66008203e-01 6.66008203e-01 6.66008203e-01\n",
      " 1.94672021e-01 1.94672021e-01 5.03439617e-01 5.03439617e-01\n",
      " 8.67623531e-02 5.03439617e-01 3.39353994e-01 3.39353994e-01\n",
      " 5.03439617e-01 1.94672021e-01 9.14694688e-01 3.39353994e-01\n",
      " 1.94672021e-01 9.14694688e-01 6.66008203e-01 9.14694688e-01\n",
      " 3.39353994e-01 6.66008203e-01 1.94672021e-01 3.39353994e-01\n",
      " 1.94672021e-01 6.66008203e-01 5.03439617e-01 5.03439617e-01\n",
      " 6.66008203e-01 9.14694688e-01 8.67623531e-02 6.66008203e-01\n",
      " 5.03439617e-01 3.39353994e-01 9.14694688e-01 1.94672021e-01\n",
      " 3.39353994e-01 8.07800970e-01 1.94672021e-01 3.39353994e-01\n",
      " 5.03439617e-01 5.03439617e-01 9.14694688e-01 5.03439617e-01\n",
      " 8.07800970e-01 1.94672021e-01 3.39353994e-01 5.03439617e-01\n",
      " 9.79153133e-01 3.39353994e-01 5.03439617e-01 5.03439617e-01\n",
      " 1.94672021e-01 1.94672021e-01 5.03439617e-01 6.66008203e-01\n",
      " 6.66008203e-01 5.03439617e-01 3.39353994e-01 3.39353994e-01\n",
      " 5.03439617e-01 6.66008203e-01 5.03439617e-01 1.94672021e-01\n",
      " 3.39353994e-01 5.03439617e-01 6.66008203e-01 5.03439617e-01\n",
      " 1.94672021e-01 8.07800970e-01 5.03439617e-01 9.14694688e-01\n",
      " 8.07800970e-01 6.66008203e-01 5.03439617e-01 8.07800970e-01\n",
      " 3.39353994e-01 5.03439617e-01 5.03439617e-01 5.03439617e-01\n",
      " 5.03439617e-01 8.07800970e-01 5.03439617e-01 5.03439617e-01\n",
      " 9.79153133e-01 8.67623531e-02 3.39353994e-01 3.39353994e-01\n",
      " 3.39353994e-01 5.03439617e-01 6.66008203e-01 3.39353994e-01\n",
      " 6.66008203e-01 9.14694688e-01 5.03439617e-01 5.03439617e-01\n",
      " 3.39353994e-01 3.39353994e-01 3.39353994e-01 9.14694688e-01\n",
      " 3.39353994e-01 5.03439617e-01 5.03439617e-01 8.07800970e-01\n",
      " 1.94672021e-01 6.66008203e-01 8.07800970e-01 8.67623531e-02\n",
      " 3.39353994e-01 8.07800970e-01 6.66008203e-01 6.66008203e-01\n",
      " 5.03439617e-01 6.66008203e-01 3.39353994e-01 6.66008203e-01\n",
      " 5.03439617e-01 1.94672021e-01 1.94672021e-01 3.39353994e-01\n",
      " 3.39353994e-01 1.94672021e-01 8.07800970e-01 5.03439617e-01\n",
      " 6.66008203e-01 6.66008203e-01 8.07800970e-01 8.07800970e-01\n",
      " 6.66008203e-01 5.03439617e-01 9.14694688e-01 3.39353994e-01\n",
      " 1.94672021e-01 5.03439617e-01 9.14694688e-01 5.03439617e-01\n",
      " 6.66008203e-01 5.03439617e-01 5.03439617e-01 6.66008203e-01\n",
      " 6.66008203e-01 3.39353994e-01 6.66008203e-01 2.37456543e-02\n",
      " 3.39353994e-01 5.03439617e-01 6.66008203e-01 6.66008203e-01\n",
      " 1.94672021e-01 5.03439617e-01 6.66008203e-01 6.66008203e-01\n",
      " 3.39353994e-01 3.39353994e-01 8.07800970e-01 1.94672021e-01\n",
      " 1.94672021e-01 1.94672021e-01 6.66008203e-01 1.94672021e-01\n",
      " 1.94672021e-01 5.03439617e-01 5.03439617e-01 5.03439617e-01\n",
      " 1.94672021e-01 6.66008203e-01 3.39353994e-01 8.07800970e-01\n",
      " 9.79153133e-01 6.66008203e-01 5.03439617e-01 5.03439617e-01\n",
      " 8.07800970e-01 8.67623531e-02 6.66008203e-01 5.03439617e-01\n",
      " 3.39353994e-01 3.39353994e-01 3.39353994e-01 5.03439617e-01\n",
      " 6.66008203e-01 5.03439617e-01 3.39353994e-01 2.37456543e-02\n",
      " 1.94672021e-01 2.37456543e-02 1.94672021e-01 8.67623531e-02\n",
      " 3.39353994e-01 6.66008203e-01 3.39353994e-01 6.66008203e-01\n",
      " 1.94672021e-01 5.03439617e-01 3.39353994e-01 1.94672021e-01\n",
      " 5.03439617e-01 9.14694688e-01 3.39353994e-01 3.39353994e-01\n",
      " 6.66008203e-01 5.03439617e-01 3.39353994e-01 5.03439617e-01\n",
      " 6.66008203e-01 8.07800970e-01 8.07800970e-01 6.66008203e-01\n",
      " 9.14694688e-01 6.66008203e-01 5.03439617e-01 6.66008203e-01\n",
      " 1.94672021e-01 8.07800970e-01 8.07800970e-01 9.14694688e-01\n",
      " 1.94672021e-01 8.07800970e-01 1.94672021e-01 3.39353994e-01\n",
      " 5.03439617e-01 5.03439617e-01 3.39353994e-01 6.66008203e-01\n",
      " 1.94672021e-01 1.94672021e-01 5.03439617e-01 2.37456543e-02\n",
      " 8.07800970e-01 9.14694688e-01 3.39353994e-01 5.03439617e-01\n",
      " 3.39353994e-01 6.66008203e-01 5.03439617e-01 5.03439617e-01\n",
      " 3.39353994e-01 3.39353994e-01 8.07800970e-01 5.03439617e-01\n",
      " 1.94672021e-01 3.39353994e-01 5.03439617e-01 5.03439617e-01\n",
      " 6.66008203e-01 8.67623531e-02 3.39353994e-01 5.03439617e-01\n",
      " 3.39353994e-01 9.79153133e-01 3.39353994e-01 3.39353994e-01\n",
      " 3.39353994e-01 3.39353994e-01 5.03439617e-01 8.67623531e-02\n",
      " 6.66008203e-01 1.94672021e-01 8.07800970e-01 3.39353994e-01\n",
      " 3.39353994e-01 1.94672021e-01 3.39353994e-01 3.39353994e-01\n",
      " 3.39353994e-01 6.66008203e-01 5.03439617e-01 9.79153133e-01\n",
      " 3.39353994e-01 8.07800970e-01 1.00000000e+00 3.39353994e-01\n",
      " 6.66008203e-01 8.07800970e-01 3.39353994e-01 1.94672021e-01\n",
      " 8.07800970e-01 5.03439617e-01 5.03439617e-01 5.03439617e-01\n",
      " 3.39353994e-01 5.03439617e-01 8.07800970e-01 6.66008203e-01\n",
      " 5.03439617e-01 3.39353994e-01 5.03439617e-01 3.39353994e-01\n",
      " 5.03439617e-01 8.67623531e-02 1.94672021e-01 3.39353994e-01\n",
      " 6.66008203e-01 3.39353994e-01 6.66008203e-01 5.03439617e-01\n",
      " 8.07800970e-01 5.03439617e-01 5.03439617e-01 6.66008203e-01\n",
      " 8.07800970e-01 5.03439617e-01 3.39353994e-01 3.39353994e-01\n",
      " 5.03439617e-01 1.94672021e-01 3.39353994e-01 6.66008203e-01\n",
      " 3.39353994e-01 6.66008203e-01 6.66008203e-01 5.03439617e-01\n",
      " 5.03439617e-01 6.66008203e-01 8.67623531e-02 1.94672021e-01\n",
      " 3.39353994e-01 9.14694688e-01 5.03439617e-01 8.07800970e-01\n",
      " 5.03439617e-01 3.39353994e-01 1.94672021e-01 5.03439617e-01\n",
      " 1.94672021e-01 8.07800970e-01 3.39353994e-01 5.03439617e-01\n",
      " 5.03439617e-01 1.94672021e-01 6.66008203e-01 5.03439617e-01\n",
      " 1.94672021e-01 5.03439617e-01 3.39353994e-01 5.03439617e-01\n",
      " 6.66008203e-01 3.39353994e-01 5.03439617e-01 6.66008203e-01\n",
      " 8.07800970e-01 8.07800970e-01 5.03439617e-01 3.39353994e-01\n",
      " 8.07800970e-01 9.14694688e-01 9.14694688e-01 5.03439617e-01\n",
      " 6.66008203e-01 6.66008203e-01 6.66008203e-01 6.66008203e-01\n",
      " 6.66008203e-01 5.03439617e-01 2.37456543e-02 8.07800970e-01\n",
      " 6.66008203e-01 1.94672021e-01 1.94672021e-01 8.67623531e-02\n",
      " 6.66008203e-01 8.67623531e-02 6.66008203e-01 8.67623531e-02\n",
      " 1.94672021e-01 6.66008203e-01 5.03439617e-01 8.07800970e-01\n",
      " 9.14694688e-01 5.03439617e-01 6.66008203e-01 9.14694688e-01\n",
      " 6.66008203e-01 1.94672021e-01 6.66008203e-01 8.07800970e-01\n",
      " 5.03439617e-01 8.07800970e-01 8.07800970e-01 8.67623531e-02\n",
      " 6.66008203e-01 5.03439617e-01 5.03439617e-01 8.07800970e-01\n",
      " 6.66008203e-01 6.66008203e-01 6.66008203e-01 6.66008203e-01\n",
      " 3.39353994e-01 1.94672021e-01 8.67623531e-02 1.94672021e-01\n",
      " 6.66008203e-01 6.66008203e-01 8.07800970e-01 8.07800970e-01\n",
      " 8.67623531e-02 1.94672021e-01 8.67623531e-02 8.07800970e-01\n",
      " 1.94672021e-01 6.66008203e-01 8.07800970e-01 1.94672021e-01\n",
      " 3.39353994e-01 5.03439617e-01 9.14694688e-01 8.07800970e-01\n",
      " 3.39353994e-01 6.66008203e-01 9.14694688e-01 6.66008203e-01\n",
      " 3.39353994e-01 2.37456543e-02 8.07800970e-01 3.39353994e-01\n",
      " 5.03439617e-01 6.66008203e-01 6.66008203e-01 5.03439617e-01\n",
      " 6.66008203e-01 6.66008203e-01 1.94672021e-01 6.66008203e-01\n",
      " 8.07800970e-01 5.03439617e-01 6.66008203e-01 5.03439617e-01\n",
      " 5.03439617e-01 2.37456543e-02 6.66008203e-01 3.35462628e-04\n",
      " 5.03439617e-01 8.67623531e-02 1.94672021e-01 6.66008203e-01\n",
      " 6.66008203e-01 3.39353994e-01 3.39353994e-01 8.07800970e-01\n",
      " 5.03439617e-01 6.66008203e-01 8.07800970e-01 8.07800970e-01\n",
      " 3.39353994e-01 1.94672021e-01 8.67623531e-02 1.94672021e-01\n",
      " 3.39353994e-01 3.39353994e-01 9.14694688e-01 3.39353994e-01\n",
      " 8.67623531e-02 3.39353994e-01 3.39353994e-01 5.03439617e-01\n",
      " 5.03439617e-01 3.39353994e-01 5.03439617e-01 8.07800970e-01\n",
      " 8.07800970e-01 5.03439617e-01 6.66008203e-01 5.03439617e-01\n",
      " 3.39353994e-01 2.37456543e-02 1.94672021e-01 3.39353994e-01\n",
      " 8.07800970e-01 5.03439617e-01 6.66008203e-01 1.94672021e-01\n",
      " 8.07800970e-01 6.66008203e-01 1.94672021e-01 5.03439617e-01\n",
      " 6.66008203e-01 1.94672021e-01 3.39353994e-01 3.39353994e-01\n",
      " 9.79153133e-01 6.66008203e-01 6.66008203e-01 3.39353994e-01\n",
      " 5.03439617e-01 6.66008203e-01 5.03439617e-01 3.39353994e-01\n",
      " 1.94672021e-01 2.37456543e-02 6.66008203e-01 9.79153133e-01\n",
      " 5.03439617e-01 8.07800970e-01 3.39353994e-01 6.66008203e-01\n",
      " 6.66008203e-01 5.03439617e-01 5.03439617e-01 9.14694688e-01\n",
      " 9.14694688e-01 5.03439617e-01 3.39353994e-01 2.37456543e-02\n",
      " 9.14694688e-01 5.03439617e-01 3.39353994e-01 3.39353994e-01\n",
      " 1.94672021e-01 1.94672021e-01 9.14694688e-01 3.39353994e-01\n",
      " 6.66008203e-01 5.03439617e-01 5.03439617e-01 3.39353994e-01\n",
      " 6.66008203e-01 1.94672021e-01 1.94672021e-01 5.03439617e-01\n",
      " 3.39353994e-01 8.07800970e-01 1.94672021e-01 6.66008203e-01\n",
      " 9.14694688e-01 3.39353994e-01 8.07800970e-01 6.66008203e-01\n",
      " 5.03439617e-01 8.07800970e-01 6.66008203e-01 1.94672021e-01\n",
      " 1.94672021e-01 1.94672021e-01 5.03439617e-01 5.03439617e-01\n",
      " 2.37456543e-02 5.03439617e-01 3.39353994e-01 8.07800970e-01\n",
      " 8.67623531e-02 1.94672021e-01 5.03439617e-01 1.94672021e-01\n",
      " 8.07800970e-01 6.66008203e-01 3.39353994e-01 5.03439617e-01\n",
      " 1.94672021e-01 5.03439617e-01 6.66008203e-01 3.39353994e-01\n",
      " 3.39353994e-01 6.66008203e-01 8.07800970e-01 5.03439617e-01\n",
      " 9.79153133e-01 3.39353994e-01 6.66008203e-01 8.67623531e-02\n",
      " 9.14694688e-01 3.39353994e-01 3.39353994e-01 3.39353994e-01\n",
      " 3.39353994e-01 1.94672021e-01 3.39353994e-01 5.03439617e-01\n",
      " 6.66008203e-01 8.07800970e-01 5.03439617e-01 5.03439617e-01\n",
      " 3.39353994e-01 5.03439617e-01 9.79153133e-01 1.94672021e-01\n",
      " 6.66008203e-01 6.66008203e-01 3.39353994e-01 5.03439617e-01\n",
      " 5.03439617e-01 6.66008203e-01 5.03439617e-01 9.14694688e-01\n",
      " 5.03439617e-01 6.66008203e-01 8.67623531e-02 5.03439617e-01\n",
      " 6.66008203e-01 3.39353994e-01 8.07800970e-01 6.66008203e-01\n",
      " 3.39353994e-01 6.66008203e-01 8.07800970e-01 5.03439617e-01\n",
      " 9.14694688e-01 8.07800970e-01 1.94672021e-01 8.07800970e-01\n",
      " 1.94672021e-01 8.07800970e-01 6.66008203e-01 8.67623531e-02\n",
      " 5.03439617e-01 8.07800970e-01 1.94672021e-01 6.66008203e-01\n",
      " 9.14694688e-01 1.94672021e-01 5.03439617e-01 6.66008203e-01\n",
      " 3.39353994e-01 3.39353994e-01 6.66008203e-01 8.67623531e-02\n",
      " 3.39353994e-01 5.03439617e-01 8.07800970e-01 6.66008203e-01\n",
      " 9.14694688e-01 5.03439617e-01 1.94672021e-01 6.66008203e-01\n",
      " 6.66008203e-01 8.67623531e-02 8.07800970e-01 5.03439617e-01\n",
      " 3.39353994e-01 6.66008203e-01 6.66008203e-01 3.39353994e-01\n",
      " 8.07800970e-01 3.39353994e-01 5.03439617e-01 6.66008203e-01\n",
      " 5.03439617e-01 5.03439617e-01 5.03439617e-01 3.39353994e-01\n",
      " 5.03439617e-01 1.94672021e-01 5.03439617e-01 5.03439617e-01\n",
      " 3.39353994e-01 5.03439617e-01 5.03439617e-01 1.94672021e-01\n",
      " 5.03439617e-01 6.66008203e-01 6.66008203e-01 8.67623531e-02\n",
      " 6.66008203e-01 5.03439617e-01 3.39353994e-01 5.03439617e-01] \n",
      " values : \n",
      " [[[-0.6478854 ]\n",
      "  [-0.64199155]\n",
      "  [-0.63818632]\n",
      "  ...\n",
      "  [-0.64042873]\n",
      "  [-0.63866571]\n",
      "  [-0.63865722]]\n",
      "\n",
      " [[-0.6478854 ]\n",
      "  [-0.64199155]\n",
      "  [-0.63818632]\n",
      "  ...\n",
      "  [-0.64042873]\n",
      "  [-0.63866571]\n",
      "  [-0.63865722]]\n",
      "\n",
      " [[-0.6478854 ]\n",
      "  [-0.64875881]\n",
      "  [-0.64963223]\n",
      "  ...\n",
      "  [-0.64042873]\n",
      "  [-0.63866571]\n",
      "  [-0.63865722]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.6478854 ]\n",
      "  [-0.64199155]\n",
      "  [-0.63818632]\n",
      "  ...\n",
      "  [-0.64042873]\n",
      "  [-0.63866571]\n",
      "  [-0.63865722]]\n",
      "\n",
      " [[-0.6478854 ]\n",
      "  [-0.64875881]\n",
      "  [-0.64963223]\n",
      "  ...\n",
      "  [-0.63824779]\n",
      "  [-0.6384525 ]\n",
      "  [-0.63865722]]\n",
      "\n",
      " [[-0.6478854 ]\n",
      "  [-0.64875881]\n",
      "  [-0.64963223]\n",
      "  ...\n",
      "  [-0.63824779]\n",
      "  [-0.6384525 ]\n",
      "  [-0.63865722]]] \n",
      " proba_labels : \n",
      " None \n",
      " \n",
      "This is prediction\n",
      "(1000, 150, 1)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/media/jacqueline/Data/InterpretabiltyTimeSeries/InterpretabilityModels/utils.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y_pred = torch.nn.functional.softmax(out).detach().numpy()\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "for i in range(len(explanations)):\n",
    "    print('class{} : '.format(i),explanations[i][0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "class0 :  [-4.72941720e-07 -1.16834867e-10 -1.77356311e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  9.86029478e-11  1.94125752e-10]\n",
      "class1 :  [-1.94125752e-10 -9.86029478e-11  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.77356311e-11\n",
      "  1.16834867e-10  4.72941720e-07]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "leftist.plot_on_sample(explained_instance.flatten(),explanations)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-4.72941720e-07 -1.16834867e-10 -1.77356311e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  9.86029478e-11  1.94125752e-10]\n",
      "-4.72941720059013e-07\n",
      "0.0\n",
      "-1.168348672894354e-10\n",
      "15.0\n",
      "-1.77356310616398e-11\n",
      "30.0\n",
      "0.0\n",
      "45.0\n",
      "0.0\n",
      "60.0\n",
      "0.0\n",
      "75.0\n",
      "0.0\n",
      "90.0\n",
      "0.0\n",
      "105.0\n",
      "9.8602947760425e-11\n",
      "120.0\n",
      "1.9412575173537976e-10\n",
      "135.0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit ('InterpretabiltyTimeSeries-y2AnfPaS': pipenv)"
  },
  "interpreter": {
   "hash": "e00113cbaa5373cd8152bdb4d99638c8137ef1c7e8ee1ddca3f93a3ba9fcdfcf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}